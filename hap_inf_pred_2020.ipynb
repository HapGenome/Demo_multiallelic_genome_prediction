{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6dc85868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyreadr\n",
      "  Downloading pyreadr-0.4.9-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (437 kB)\n",
      "     |████████████████████████████████| 437 kB 26.0 MB/s            \n",
      "\u001b[?25hCollecting lightgbm\n",
      "  Downloading lightgbm-4.0.0.tar.gz (1.7 MB)\n",
      "     |████████████████████████████████| 1.7 MB 58.3 MB/s            \n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: pandas>=1.2.0 in /opt/conda/lib/python3.8/site-packages (from pyreadr) (1.3.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.8/site-packages (from lightgbm) (1.21.1)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.8/site-packages (from lightgbm) (1.6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.8/site-packages (from pandas>=1.2.0->pyreadr) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.8/site-packages (from pandas>=1.2.0->pyreadr) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.7.3->pandas>=1.2.0->pyreadr) (1.15.0)\n",
      "Building wheels for collected packages: lightgbm\n",
      "  Building wheel for lightgbm (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for lightgbm: filename=lightgbm-4.0.0-py3-none-manylinux_2_27_x86_64.whl size=2462978 sha256=b3376d5f0420fd953d805750577446f99f505c8c3b411b5e0fe5a446b8fa2a8c\n",
      "  Stored in directory: /home/ubuntu/.cache/pip/wheels/e3/b8/97/5e260d77a9cfac3783b63bc55226ba7e02db270a2779635d26\n",
      "Successfully built lightgbm\n",
      "Installing collected packages: pyreadr, lightgbm\n",
      "Successfully installed lightgbm-4.0.0 pyreadr-0.4.9\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#install pyreadr on terminal\n",
    "! pip install pyreadr lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09fb7310",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from termcolor import colored\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures, OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score, silhouette_score\n",
    "from sklearn.metrics import confusion_matrix,precision_recall_curve, roc_curve\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score,accuracy_score, roc_auc_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.linear_model import SGDRegressor, SGDClassifier\n",
    "from sklearn.linear_model import Ridge,Lasso,ElasticNet\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, BaggingClassifier \n",
    "from sklearn.ensemble import BaggingClassifier, GradientBoostingRegressor\n",
    "from sklearn.svm import SVC,SVR\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import PCA, IncrementalPCA, KernelPCA\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans, DBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3003c8f",
   "metadata": {},
   "source": [
    "# Haplotype model - Categorical variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8bca64b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyreadr\n",
    "\n",
    "# read in female data\n",
    "result = pyreadr.read_r('/mnt/ML_HBLUP/NA_RM105_110_115/data/dummyMatrix_female.rds') # also works for RData\n",
    "# done! \n",
    "# result is a dictionary where keys are the name of objects and the values python\n",
    "# objects. In the case of Rds there is only one object with None as key\n",
    "femaleData = result[None] # extract the pandas data frame \n",
    "\n",
    "# read in male data\n",
    "result = pyreadr.read_r('/mnt/ML_HBLUP/NA_RM105_110_115/data/dummyMatrix_male.rds') # also works for RData\n",
    "maleData = result[None] # extract the pandas data frame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffdf4c7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HB1__1067-1</th>\n",
       "      <th>HB1__32843</th>\n",
       "      <th>HB1__64DWA2</th>\n",
       "      <th>HB1__B73</th>\n",
       "      <th>HB1__MANS</th>\n",
       "      <th>HB1__NA</th>\n",
       "      <th>HB1__WDAQ2</th>\n",
       "      <th>HB2__1067-1</th>\n",
       "      <th>HB2__32843</th>\n",
       "      <th>HB2__64DWA2</th>\n",
       "      <th>...</th>\n",
       "      <th>HB17115__7797</th>\n",
       "      <th>HB17115__B73</th>\n",
       "      <th>HB17115__NA</th>\n",
       "      <th>HB17115__RQAA8</th>\n",
       "      <th>HB17116__2FACC</th>\n",
       "      <th>HB17116__7797</th>\n",
       "      <th>HB17116__B73</th>\n",
       "      <th>HB17116__FBMU</th>\n",
       "      <th>HB17116__NA</th>\n",
       "      <th>HB17116__RQAA8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>01DHD10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01DHD16</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01DKD2-BGL-T1A1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01DKD2-NQR-T1B1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01DKD2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 54753 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 HB1__1067-1  HB1__32843  HB1__64DWA2  HB1__B73  HB1__MANS  \\\n",
       "01DHD10                  0.0         0.0          0.0       2.0        0.0   \n",
       "01DHD16                  2.0         0.0          0.0       0.0        0.0   \n",
       "01DKD2-BGL-T1A1          0.0         0.0          0.0       0.0        0.0   \n",
       "01DKD2-NQR-T1B1          0.0         0.0          0.0       0.0        0.0   \n",
       "01DKD2                   0.0         0.0          0.0       2.0        0.0   \n",
       "\n",
       "                 HB1__NA  HB1__WDAQ2  HB2__1067-1  HB2__32843  HB2__64DWA2  \\\n",
       "01DHD10              0.0         0.0          0.0         0.0          0.0   \n",
       "01DHD16              0.0         0.0          2.0         0.0          0.0   \n",
       "01DKD2-BGL-T1A1      2.0         0.0          0.0         0.0          0.0   \n",
       "01DKD2-NQR-T1B1      2.0         0.0          0.0         0.0          0.0   \n",
       "01DKD2               0.0         0.0          0.0         0.0          0.0   \n",
       "\n",
       "                 ...  HB17115__7797  HB17115__B73  HB17115__NA  \\\n",
       "01DHD10          ...            0.0           0.0          2.0   \n",
       "01DHD16          ...            0.0           0.0          2.0   \n",
       "01DKD2-BGL-T1A1  ...            0.0           2.0          0.0   \n",
       "01DKD2-NQR-T1B1  ...            0.0           2.0          0.0   \n",
       "01DKD2           ...            0.0           2.0          0.0   \n",
       "\n",
       "                 HB17115__RQAA8  HB17116__2FACC  HB17116__7797  HB17116__B73  \\\n",
       "01DHD10                     0.0             0.0            0.0           0.0   \n",
       "01DHD16                     0.0             0.0            0.0           0.0   \n",
       "01DKD2-BGL-T1A1             0.0             0.0            0.0           2.0   \n",
       "01DKD2-NQR-T1B1             0.0             0.0            0.0           2.0   \n",
       "01DKD2                      0.0             0.0            0.0           2.0   \n",
       "\n",
       "                 HB17116__FBMU  HB17116__NA  HB17116__RQAA8  \n",
       "01DHD10                    0.0          2.0             0.0  \n",
       "01DHD16                    0.0          2.0             0.0  \n",
       "01DKD2-BGL-T1A1            0.0          0.0             0.0  \n",
       "01DKD2-NQR-T1B1            0.0          0.0             0.0  \n",
       "01DKD2                     0.0          0.0             0.0  \n",
       "\n",
       "[5 rows x 54753 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "femaleData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5503f2eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HB1__01HGI4</th>\n",
       "      <th>HB1__610</th>\n",
       "      <th>HB1__B14</th>\n",
       "      <th>HB1__LH287</th>\n",
       "      <th>HB1__M3AG-3</th>\n",
       "      <th>HB1__NA</th>\n",
       "      <th>HB1__OH43AE1</th>\n",
       "      <th>HB1__PH207</th>\n",
       "      <th>HB2__610</th>\n",
       "      <th>HB2__B14</th>\n",
       "      <th>...</th>\n",
       "      <th>HB17114__OH07</th>\n",
       "      <th>HB17114__PH207</th>\n",
       "      <th>HB17115__LH123</th>\n",
       "      <th>HB17115__NA</th>\n",
       "      <th>HB17115__OH07</th>\n",
       "      <th>HB17115__TA1180</th>\n",
       "      <th>HB17116__LH123</th>\n",
       "      <th>HB17116__NA</th>\n",
       "      <th>HB17116__OH07</th>\n",
       "      <th>HB17116__PH207</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LH287</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83INI14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17IFI6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DILU757</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GEJO564</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 54845 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         HB1__01HGI4  HB1__610  HB1__B14  HB1__LH287  HB1__M3AG-3  HB1__NA  \\\n",
       "LH287            0.0       0.0       0.0         2.0          0.0      0.0   \n",
       "83INI14          0.0       0.0       0.0         0.0          0.0      0.0   \n",
       "17IFI6           0.0       0.0       0.0         0.0          0.0      0.0   \n",
       "DILU757          0.0       0.0       0.0         0.0          0.0      0.0   \n",
       "GEJO564          2.0       0.0       0.0         0.0          0.0      0.0   \n",
       "\n",
       "         HB1__OH43AE1  HB1__PH207  HB2__610  HB2__B14  ...  HB17114__OH07  \\\n",
       "LH287             0.0         0.0       0.0       0.0  ...            0.0   \n",
       "83INI14           0.0         2.0       0.0       0.0  ...            0.0   \n",
       "17IFI6            0.0         2.0       0.0       0.0  ...            0.0   \n",
       "DILU757           0.0         2.0       0.0       0.0  ...            0.0   \n",
       "GEJO564           0.0         0.0       0.0       0.0  ...            0.0   \n",
       "\n",
       "         HB17114__PH207  HB17115__LH123  HB17115__NA  HB17115__OH07  \\\n",
       "LH287               0.0             0.0          2.0            0.0   \n",
       "83INI14             2.0             0.0          0.0            0.0   \n",
       "17IFI6              2.0             0.0          0.0            0.0   \n",
       "DILU757             0.0             0.0          0.0            0.0   \n",
       "GEJO564             0.0             2.0          0.0            0.0   \n",
       "\n",
       "         HB17115__TA1180  HB17116__LH123  HB17116__NA  HB17116__OH07  \\\n",
       "LH287                0.0             0.0          2.0            0.0   \n",
       "83INI14              0.0             0.0          0.0            0.0   \n",
       "17IFI6               0.0             0.0          0.0            0.0   \n",
       "DILU757              0.0             0.0          0.0            0.0   \n",
       "GEJO564              0.0             2.0          0.0            0.0   \n",
       "\n",
       "         HB17116__PH207  \n",
       "LH287               0.0  \n",
       "83INI14             2.0  \n",
       "17IFI6              2.0  \n",
       "DILU757             0.0  \n",
       "GEJO564             0.0  \n",
       "\n",
       "[5 rows x 54845 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maleData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17eab1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add suffix\n",
    "femaleData.columns += '_f'\n",
    "maleData.columns += '_m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71eb3f47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HB1__01HGI4_m</th>\n",
       "      <th>HB1__610_m</th>\n",
       "      <th>HB1__B14_m</th>\n",
       "      <th>HB1__LH287_m</th>\n",
       "      <th>HB1__M3AG-3_m</th>\n",
       "      <th>HB1__NA_m</th>\n",
       "      <th>HB1__OH43AE1_m</th>\n",
       "      <th>HB1__PH207_m</th>\n",
       "      <th>HB2__610_m</th>\n",
       "      <th>HB2__B14_m</th>\n",
       "      <th>...</th>\n",
       "      <th>HB17114__OH07_m</th>\n",
       "      <th>HB17114__PH207_m</th>\n",
       "      <th>HB17115__LH123_m</th>\n",
       "      <th>HB17115__NA_m</th>\n",
       "      <th>HB17115__OH07_m</th>\n",
       "      <th>HB17115__TA1180_m</th>\n",
       "      <th>HB17116__LH123_m</th>\n",
       "      <th>HB17116__NA_m</th>\n",
       "      <th>HB17116__OH07_m</th>\n",
       "      <th>HB17116__PH207_m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LH287</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83INI14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17IFI6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DILU757</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GEJO564</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 54845 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         HB1__01HGI4_m  HB1__610_m  HB1__B14_m  HB1__LH287_m  HB1__M3AG-3_m  \\\n",
       "LH287              0.0         0.0         0.0           2.0            0.0   \n",
       "83INI14            0.0         0.0         0.0           0.0            0.0   \n",
       "17IFI6             0.0         0.0         0.0           0.0            0.0   \n",
       "DILU757            0.0         0.0         0.0           0.0            0.0   \n",
       "GEJO564            2.0         0.0         0.0           0.0            0.0   \n",
       "\n",
       "         HB1__NA_m  HB1__OH43AE1_m  HB1__PH207_m  HB2__610_m  HB2__B14_m  ...  \\\n",
       "LH287          0.0             0.0           0.0         0.0         0.0  ...   \n",
       "83INI14        0.0             0.0           2.0         0.0         0.0  ...   \n",
       "17IFI6         0.0             0.0           2.0         0.0         0.0  ...   \n",
       "DILU757        0.0             0.0           2.0         0.0         0.0  ...   \n",
       "GEJO564        0.0             0.0           0.0         0.0         0.0  ...   \n",
       "\n",
       "         HB17114__OH07_m  HB17114__PH207_m  HB17115__LH123_m  HB17115__NA_m  \\\n",
       "LH287                0.0               0.0               0.0            2.0   \n",
       "83INI14              0.0               2.0               0.0            0.0   \n",
       "17IFI6               0.0               2.0               0.0            0.0   \n",
       "DILU757              0.0               0.0               0.0            0.0   \n",
       "GEJO564              0.0               0.0               2.0            0.0   \n",
       "\n",
       "         HB17115__OH07_m  HB17115__TA1180_m  HB17116__LH123_m  HB17116__NA_m  \\\n",
       "LH287                0.0                0.0               0.0            2.0   \n",
       "83INI14              0.0                0.0               0.0            0.0   \n",
       "17IFI6               0.0                0.0               0.0            0.0   \n",
       "DILU757              0.0                0.0               0.0            0.0   \n",
       "GEJO564              0.0                0.0               2.0            0.0   \n",
       "\n",
       "         HB17116__OH07_m  HB17116__PH207_m  \n",
       "LH287                0.0               0.0  \n",
       "83INI14              0.0               2.0  \n",
       "17IFI6               0.0               2.0  \n",
       "DILU757              0.0               0.0  \n",
       "GEJO564              0.0               0.0  \n",
       "\n",
       "[5 rows x 54845 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maleData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ad03751",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HB1__1067-1_f</th>\n",
       "      <th>HB1__32843_f</th>\n",
       "      <th>HB1__64DWA2_f</th>\n",
       "      <th>HB1__B73_f</th>\n",
       "      <th>HB1__MANS_f</th>\n",
       "      <th>HB1__NA_f</th>\n",
       "      <th>HB1__WDAQ2_f</th>\n",
       "      <th>HB2__1067-1_f</th>\n",
       "      <th>HB2__32843_f</th>\n",
       "      <th>HB2__64DWA2_f</th>\n",
       "      <th>...</th>\n",
       "      <th>HB17115__7797_f</th>\n",
       "      <th>HB17115__B73_f</th>\n",
       "      <th>HB17115__NA_f</th>\n",
       "      <th>HB17115__RQAA8_f</th>\n",
       "      <th>HB17116__2FACC_f</th>\n",
       "      <th>HB17116__7797_f</th>\n",
       "      <th>HB17116__B73_f</th>\n",
       "      <th>HB17116__FBMU_f</th>\n",
       "      <th>HB17116__NA_f</th>\n",
       "      <th>HB17116__RQAA8_f</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>01DHD10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01DHD16</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01DKD2-BGL-T1A1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01DKD2-NQR-T1B1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01DKD2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 54753 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 HB1__1067-1_f  HB1__32843_f  HB1__64DWA2_f  HB1__B73_f  \\\n",
       "01DHD10                    0.0           0.0            0.0         2.0   \n",
       "01DHD16                    2.0           0.0            0.0         0.0   \n",
       "01DKD2-BGL-T1A1            0.0           0.0            0.0         0.0   \n",
       "01DKD2-NQR-T1B1            0.0           0.0            0.0         0.0   \n",
       "01DKD2                     0.0           0.0            0.0         2.0   \n",
       "\n",
       "                 HB1__MANS_f  HB1__NA_f  HB1__WDAQ2_f  HB2__1067-1_f  \\\n",
       "01DHD10                  0.0        0.0           0.0            0.0   \n",
       "01DHD16                  0.0        0.0           0.0            2.0   \n",
       "01DKD2-BGL-T1A1          0.0        2.0           0.0            0.0   \n",
       "01DKD2-NQR-T1B1          0.0        2.0           0.0            0.0   \n",
       "01DKD2                   0.0        0.0           0.0            0.0   \n",
       "\n",
       "                 HB2__32843_f  HB2__64DWA2_f  ...  HB17115__7797_f  \\\n",
       "01DHD10                   0.0            0.0  ...              0.0   \n",
       "01DHD16                   0.0            0.0  ...              0.0   \n",
       "01DKD2-BGL-T1A1           0.0            0.0  ...              0.0   \n",
       "01DKD2-NQR-T1B1           0.0            0.0  ...              0.0   \n",
       "01DKD2                    0.0            0.0  ...              0.0   \n",
       "\n",
       "                 HB17115__B73_f  HB17115__NA_f  HB17115__RQAA8_f  \\\n",
       "01DHD10                     0.0            2.0               0.0   \n",
       "01DHD16                     0.0            2.0               0.0   \n",
       "01DKD2-BGL-T1A1             2.0            0.0               0.0   \n",
       "01DKD2-NQR-T1B1             2.0            0.0               0.0   \n",
       "01DKD2                      2.0            0.0               0.0   \n",
       "\n",
       "                 HB17116__2FACC_f  HB17116__7797_f  HB17116__B73_f  \\\n",
       "01DHD10                       0.0              0.0             0.0   \n",
       "01DHD16                       0.0              0.0             0.0   \n",
       "01DKD2-BGL-T1A1               0.0              0.0             2.0   \n",
       "01DKD2-NQR-T1B1               0.0              0.0             2.0   \n",
       "01DKD2                        0.0              0.0             2.0   \n",
       "\n",
       "                 HB17116__FBMU_f  HB17116__NA_f  HB17116__RQAA8_f  \n",
       "01DHD10                      0.0            2.0               0.0  \n",
       "01DHD16                      0.0            2.0               0.0  \n",
       "01DKD2-BGL-T1A1              0.0            0.0               0.0  \n",
       "01DKD2-NQR-T1B1              0.0            0.0               0.0  \n",
       "01DKD2                       0.0            0.0               0.0  \n",
       "\n",
       "[5 rows x 54753 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "femaleData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf6be371",
   "metadata": {},
   "outputs": [],
   "source": [
    "allHapFemales = femaleData.index\n",
    "allHapMales = maleData.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6ebd0ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the train data and test data\n",
    "trainPheno = pd.read_csv('/mnt/ML_HBLUP/NA_RM105_110_115/data/train_phenoData_NA_Corn_hblup_2015-2020_ALL_UDR_105-110-115.csv')\n",
    "testPheno = pd.read_csv('/mnt/code/pred_2020/NA_Corn_hblup_2020_ALL_UDR_105-110-115_RM.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "66f13b00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LINE_NAME</th>\n",
       "      <th>FEMALE</th>\n",
       "      <th>MALE</th>\n",
       "      <th>YLD_BE_BLUP</th>\n",
       "      <th>MST_BE_BLUP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01DHD10+LH287</td>\n",
       "      <td>01DHD10</td>\n",
       "      <td>LH287</td>\n",
       "      <td>-15.661</td>\n",
       "      <td>-0.219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01DHD16+83INI14</td>\n",
       "      <td>01DHD16</td>\n",
       "      <td>83INI14</td>\n",
       "      <td>-41.839</td>\n",
       "      <td>-4.254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01DKD2-BGL-T1A1+17IFI6</td>\n",
       "      <td>01DKD2-BGL-T1A1</td>\n",
       "      <td>17IFI6</td>\n",
       "      <td>-30.021</td>\n",
       "      <td>-3.251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01DKD2-BGL-T1A1+DILU757</td>\n",
       "      <td>01DKD2-BGL-T1A1</td>\n",
       "      <td>DILU757</td>\n",
       "      <td>8.279</td>\n",
       "      <td>1.769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01DKD2-BGL-T1A1+GEJO564</td>\n",
       "      <td>01DKD2-BGL-T1A1</td>\n",
       "      <td>GEJO564</td>\n",
       "      <td>4.171</td>\n",
       "      <td>1.519</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 LINE_NAME           FEMALE     MALE  YLD_BE_BLUP  MST_BE_BLUP\n",
       "0            01DHD10+LH287          01DHD10    LH287      -15.661       -0.219\n",
       "1          01DHD16+83INI14          01DHD16  83INI14      -41.839       -4.254\n",
       "2   01DKD2-BGL-T1A1+17IFI6  01DKD2-BGL-T1A1   17IFI6      -30.021       -3.251\n",
       "3  01DKD2-BGL-T1A1+DILU757  01DKD2-BGL-T1A1  DILU757        8.279        1.769\n",
       "4  01DKD2-BGL-T1A1+GEJO564  01DKD2-BGL-T1A1  GEJO564        4.171        1.519"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainPheno.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5e6e4fd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LINE_NAME</th>\n",
       "      <th>FEMALE</th>\n",
       "      <th>MALE</th>\n",
       "      <th>YLD_BE_BLUP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JEDE424+JYLV1963</td>\n",
       "      <td>JEDE424</td>\n",
       "      <td>JYLV1963</td>\n",
       "      <td>-0.983249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GIDA1530+HILW1982</td>\n",
       "      <td>GIDA1530</td>\n",
       "      <td>HILW1982</td>\n",
       "      <td>-0.008326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HUKI1698+DINO359</td>\n",
       "      <td>HUKI1698</td>\n",
       "      <td>DINO359</td>\n",
       "      <td>1.929877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JYDD1826+GALV1529</td>\n",
       "      <td>JYDD1826</td>\n",
       "      <td>GALV1529</td>\n",
       "      <td>-1.938917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HIQO1921+HULU1619</td>\n",
       "      <td>HIQO1921</td>\n",
       "      <td>HULU1619</td>\n",
       "      <td>-2.036041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           LINE_NAME    FEMALE      MALE  YLD_BE_BLUP\n",
       "0   JEDE424+JYLV1963   JEDE424  JYLV1963    -0.983249\n",
       "1  GIDA1530+HILW1982  GIDA1530  HILW1982    -0.008326\n",
       "2   HUKI1698+DINO359  HUKI1698   DINO359     1.929877\n",
       "3  JYDD1826+GALV1529  JYDD1826  GALV1529    -1.938917\n",
       "4  HIQO1921+HULU1619  HIQO1921  HULU1619    -2.036041"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testPheno.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "483406f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter trainData by selecting hybrids with both female and male are included in haplotypdata\n",
    "# and Observation is not NA\n",
    "trainPheno = trainPheno[(trainPheno['FEMALE'].isin(allHapFemales)) & trainPheno['MALE'].isin(allHapMales) & trainPheno['YLD_BE_BLUP'].notna()]\n",
    "testPheno = testPheno[testPheno['FEMALE'].isin(allHapFemales) & testPheno['MALE'].isin(allHapMales) & testPheno['YLD_BE_BLUP'].notna()]\n",
    "\n",
    "# drop duplicated rows\n",
    "trainPheno = trainPheno.drop_duplicates()\n",
    "testPheno = testPheno.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "19a414b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33475, 5)\n",
      "(9242, 4)\n"
     ]
    }
   ],
   "source": [
    "print(trainPheno.shape)\n",
    "print(testPheno.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b00220ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter trainPheno to remove overlapped lines with testPheno\n",
    "testPheno = trainPheno[trainPheno['LINE_NAME'].isin(testPheno['LINE_NAME'])]\n",
    "trainPheno = trainPheno[~trainPheno['LINE_NAME'].isin(testPheno['LINE_NAME'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "62b48330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24236, 5)\n",
      "(9239, 5)\n"
     ]
    }
   ],
   "source": [
    "print(trainPheno.shape)\n",
    "print(testPheno.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "27dd4a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct haplotype data for test and train data\n",
    "trainHap = pd.concat([femaleData.loc[trainPheno['FEMALE'],:].reset_index(drop=True),\n",
    "                      maleData.loc[trainPheno['MALE'],:].reset_index(drop=True)],axis=1)\n",
    "trainHap = trainHap / 2\n",
    "\n",
    "testHap = pd.concat([femaleData.loc[testPheno['FEMALE'],:].reset_index(drop=True),\n",
    "                     maleData.loc[testPheno['MALE'],:].reset_index(drop=True)],axis=1)\n",
    "testHap = testHap / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a1ea34a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splite the train data into train, validationa and test\n",
    "seed = 20230510\n",
    "np.random.seed(seed)\n",
    "X_train, X_val, y_train, y_val = train_test_split(trainHap, trainPheno['YLD_BE_BLUP'], test_size=0.1, random_state=seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c283d56a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21812, 109598)\n",
      "(2424, 109598)\n",
      "(9239, 109598)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(testHap.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5c29fc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to return correlation and rmse\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "metrics = pd.DataFrame(columns=['Method', 'RMSE_train', 'RMSE_val','RMSE_test','corr_train','corr_val','corr_test'])\n",
    "def pred_rmse_corr(modelRes,modelName,X_train,y_train,X_val,y_val,X_test,y_test,metrics):\n",
    "    pred_train = modelRes.predict(X_train)\n",
    "    pred_val = modelRes.predict(X_val)\n",
    "    pred_test = modelRes.predict(X_test)\n",
    "\n",
    "    rmse_train = mean_squared_error(y_train, pred_train, squared=False)\n",
    "    rmse_val = mean_squared_error(y_val,pred_val, squared=False)\n",
    "    rmse_test = mean_squared_error(y_test, pred_test, squared=False)\n",
    "\n",
    "    corr_train, p_value_train = pearsonr(y_train.ravel(), pred_train.ravel())\n",
    "    corr_val, p_value_val = pearsonr(y_val.ravel(), pred_val.ravel())\n",
    "    corr_test, p_value_test = pearsonr(y_test.ravel(), pred_test.ravel())\n",
    "\n",
    "\n",
    "    metrics_curr_cv = pd.DataFrame(data={'Method': modelName, 'RMSE_train': [rmse_train], 'corr_train': [corr_train],\n",
    "                                     'RMSE_val' : [rmse_val], 'corr_val' : [corr_val], \n",
    "                                     'RMSE_test' : [rmse_test], 'corr_test' : [corr_test]})\n",
    "\n",
    "    metrics = pd.concat([metrics, metrics_curr_cv], axis=0)\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0bb1b6",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ca24c742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to install lightgbm from terminal: sudo pip install lightgbm\n",
    "import lightgbm as lgb\n",
    "\n",
    "gbm = lgb.LGBMRegressor(num_leaves=30,\n",
    "                        learning_rate=0.1,\n",
    "                        n_estimators=900,\n",
    "                       bagging_fraction =  0.7,\n",
    "                       feature_fraction = 0.5,\n",
    "                       objective = \"regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a0d822d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 18.374392 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 275400\n",
      "[LightGBM] [Info] Number of data points in the train set: 21812, number of used features: 109579\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Info] Start training from score 4.967134\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[470]\tvalid_0's l2: 16.5573\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(bagging_fraction=0.7, feature_fraction=0.5, n_estimators=900,\n",
       "              num_leaves=30, objective='regression')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm.fit(X_train, y_train,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        eval_metric='mse',\n",
    "        callbacks=[lgb.early_stopping(5)])\n",
    "\n",
    "\n",
    "\n",
    "# load model later\n",
    "    #model = lightgbm.Booster(model_file='file.txt')\n",
    "    #model.predict(predict[num_columns])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "51f2af68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lightgbm.basic.Booster at 0x7f64da04ad00>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save model\n",
    "gbm.booster_.save_model('/mnt/code/pred_2020/models/hap_lgbm_2020.txt')\n",
    "\n",
    "# load the saved model\n",
    "# gbm = lgb.Booster(model_file='/mnt/ML_HBLUP/NA_RM105_110_115/models/hap_lgbm_2020.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "97dd50ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>RMSE_train</th>\n",
       "      <th>RMSE_val</th>\n",
       "      <th>RMSE_test</th>\n",
       "      <th>corr_train</th>\n",
       "      <th>corr_val</th>\n",
       "      <th>corr_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LightGBM_hapCat</td>\n",
       "      <td>2.713939</td>\n",
       "      <td>4.069071</td>\n",
       "      <td>8.249353</td>\n",
       "      <td>0.971496</td>\n",
       "      <td>0.928069</td>\n",
       "      <td>0.798767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Method  RMSE_train  RMSE_val  RMSE_test  corr_train  corr_val  \\\n",
       "0  LightGBM_hapCat    2.713939  4.069071   8.249353    0.971496  0.928069   \n",
       "\n",
       "   corr_test  \n",
       "0   0.798767  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# output prediction result\n",
    "metrics = pred_rmse_corr(gbm,'LightGBM_hapCat',X_train,y_train,\n",
    "                         X_val,y_val,testHap,testPheno['YLD_BE_BLUP'],metrics)\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22279fc2",
   "metadata": {},
   "source": [
    "## Neural network - DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "85ff17c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-15 16:15:43.961180: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/oracle/instantclient_12_1:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/amd64/server:\n",
      "2023-08-15 16:15:43.961264: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fbd2a51d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-15 16:16:37.386292: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-08-15 16:16:37.386960: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/oracle/instantclient_12_1:/usr/lib/jvm/java-8-openjdk-amd64/jre/lib/amd64/server:\n",
      "2023-08-15 16:16:37.387006: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-08-15 16:16:37.387050: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (run-64db90884f722c0cf93dc7b0-2pqtb): /proc/driver/nvidia/version does not exist\n",
      "2023-08-15 16:16:37.387365: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-15 16:16:37.389925: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2023-08-15 16:16:55.785916: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 19124412608 exceeds 10% of free system memory.\n",
      "2023-08-15 16:17:07.563507: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2023-08-15 16:17:07.582680: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2199985000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "682/682 [==============================] - 23s 33ms/step - loss: 60.5095 - val_loss: 32.1668\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 32.16682, saving model to /mnt/code/pred_2020/models/dnn_train_2020.h5\n",
      "Epoch 2/50\n",
      "682/682 [==============================] - 19s 28ms/step - loss: 32.2056 - val_loss: 31.8756\n",
      "\n",
      "Epoch 00002: val_loss improved from 32.16682 to 31.87557, saving model to /mnt/code/pred_2020/models/dnn_train_2020.h5\n",
      "Epoch 3/50\n",
      "682/682 [==============================] - 19s 28ms/step - loss: 30.4800 - val_loss: 34.6853\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 31.87557\n",
      "Epoch 4/50\n",
      "682/682 [==============================] - 20s 29ms/step - loss: 26.4703 - val_loss: 30.9900\n",
      "\n",
      "Epoch 00004: val_loss improved from 31.87557 to 30.99000, saving model to /mnt/code/pred_2020/models/dnn_train_2020.h5\n",
      "Epoch 5/50\n",
      "682/682 [==============================] - 20s 29ms/step - loss: 22.8002 - val_loss: 25.9009\n",
      "\n",
      "Epoch 00005: val_loss improved from 30.99000 to 25.90093, saving model to /mnt/code/pred_2020/models/dnn_train_2020.h5\n",
      "Epoch 6/50\n",
      "682/682 [==============================] - 19s 29ms/step - loss: 21.6899 - val_loss: 24.7204\n",
      "\n",
      "Epoch 00006: val_loss improved from 25.90093 to 24.72042, saving model to /mnt/code/pred_2020/models/dnn_train_2020.h5\n",
      "Epoch 7/50\n",
      "682/682 [==============================] - 19s 28ms/step - loss: 20.7762 - val_loss: 24.8334\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 24.72042\n",
      "Epoch 8/50\n",
      "682/682 [==============================] - 20s 29ms/step - loss: 20.0331 - val_loss: 22.6614\n",
      "\n",
      "Epoch 00008: val_loss improved from 24.72042 to 22.66136, saving model to /mnt/code/pred_2020/models/dnn_train_2020.h5\n",
      "Epoch 9/50\n",
      "682/682 [==============================] - 19s 28ms/step - loss: 18.6090 - val_loss: 22.6835\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 22.66136\n",
      "Epoch 10/50\n",
      "682/682 [==============================] - 19s 28ms/step - loss: 18.2001 - val_loss: 25.0953\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 22.66136\n",
      "Epoch 11/50\n",
      "682/682 [==============================] - 20s 29ms/step - loss: 17.0930 - val_loss: 21.7001\n",
      "\n",
      "Epoch 00011: val_loss improved from 22.66136 to 21.70008, saving model to /mnt/code/pred_2020/models/dnn_train_2020.h5\n",
      "Epoch 12/50\n",
      "682/682 [==============================] - 19s 28ms/step - loss: 16.9772 - val_loss: 23.2151\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 21.70008\n",
      "Epoch 13/50\n",
      "682/682 [==============================] - 19s 28ms/step - loss: 16.8907 - val_loss: 21.9981\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 21.70008\n",
      "Epoch 14/50\n",
      "682/682 [==============================] - 19s 28ms/step - loss: 15.5360 - val_loss: 21.1609\n",
      "\n",
      "Epoch 00014: val_loss improved from 21.70008 to 21.16092, saving model to /mnt/code/pred_2020/models/dnn_train_2020.h5\n",
      "Epoch 15/50\n",
      "682/682 [==============================] - 20s 29ms/step - loss: 15.2933 - val_loss: 22.6213\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 21.16092\n",
      "Epoch 16/50\n",
      "682/682 [==============================] - 19s 28ms/step - loss: 14.0382 - val_loss: 20.8629\n",
      "\n",
      "Epoch 00016: val_loss improved from 21.16092 to 20.86286, saving model to /mnt/code/pred_2020/models/dnn_train_2020.h5\n",
      "Epoch 17/50\n",
      "682/682 [==============================] - 19s 28ms/step - loss: 14.9770 - val_loss: 20.8600\n",
      "\n",
      "Epoch 00017: val_loss improved from 20.86286 to 20.86001, saving model to /mnt/code/pred_2020/models/dnn_train_2020.h5\n",
      "Epoch 18/50\n",
      "682/682 [==============================] - 19s 28ms/step - loss: 14.1273 - val_loss: 20.1150\n",
      "\n",
      "Epoch 00018: val_loss improved from 20.86001 to 20.11502, saving model to /mnt/code/pred_2020/models/dnn_train_2020.h5\n",
      "Epoch 19/50\n",
      "682/682 [==============================] - 20s 29ms/step - loss: 14.0034 - val_loss: 20.5684\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 20.11502\n",
      "Epoch 20/50\n",
      "682/682 [==============================] - 19s 28ms/step - loss: 13.4167 - val_loss: 19.6965\n",
      "\n",
      "Epoch 00020: val_loss improved from 20.11502 to 19.69653, saving model to /mnt/code/pred_2020/models/dnn_train_2020.h5\n",
      "Epoch 21/50\n",
      "682/682 [==============================] - 19s 28ms/step - loss: 13.4892 - val_loss: 20.0497\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 19.69653\n",
      "Epoch 22/50\n",
      "682/682 [==============================] - 20s 29ms/step - loss: 13.7735 - val_loss: 18.9313\n",
      "\n",
      "Epoch 00022: val_loss improved from 19.69653 to 18.93134, saving model to /mnt/code/pred_2020/models/dnn_train_2020.h5\n",
      "Epoch 23/50\n",
      "682/682 [==============================] - 19s 28ms/step - loss: 12.9933 - val_loss: 20.8323\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 18.93134\n",
      "Epoch 24/50\n",
      "682/682 [==============================] - 19s 28ms/step - loss: 12.6537 - val_loss: 22.1889\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 18.93134\n",
      "Epoch 25/50\n",
      "682/682 [==============================] - 20s 29ms/step - loss: 12.7878 - val_loss: 19.3583\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 18.93134\n",
      "Epoch 26/50\n",
      "682/682 [==============================] - 19s 28ms/step - loss: 12.1292 - val_loss: 19.7442\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 18.93134\n",
      "Epoch 27/50\n",
      "682/682 [==============================] - 19s 28ms/step - loss: 12.2055 - val_loss: 19.8995\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 18.93134\n",
      "Epoch 28/50\n",
      "682/682 [==============================] - 19s 28ms/step - loss: 12.2963 - val_loss: 19.6249\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 18.93134\n",
      "Epoch 29/50\n",
      "682/682 [==============================] - 20s 29ms/step - loss: 11.6603 - val_loss: 20.2026\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 18.93134\n",
      "Epoch 30/50\n",
      "682/682 [==============================] - 19s 29ms/step - loss: 11.8747 - val_loss: 19.3668\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 18.93134\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(20230516)\n",
    "\n",
    "DL_model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[X_train.shape[1]], name = 'input_layer'),\n",
    "    keras.layers.Dense(100, activation=\"relu\", name = 'hidden_layer1'),\n",
    "    keras.layers.Dense(300, activation=\"relu\", name = 'hidden_layer2'),\n",
    "    keras.layers.Dense(1, name = 'output_layer')\n",
    "])\n",
    "\n",
    "DL_model.compile(loss=\"mean_squared_error\",optimizer=tf.keras.optimizers.Adam(0.001)) \n",
    "\n",
    "# define the checkpoint\n",
    "filepath = \"/mnt/code/pred_2020/models/hap_dnn_2020.h5\"\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "early_stopping = keras.callbacks.EarlyStopping(patience=8,restore_best_weights=True)\n",
    "callbacks_list = [checkpoint,early_stopping]\n",
    "\n",
    "# fit the model\n",
    "history = DL_model.fit(X_train,y_train,epochs=50,validation_data = (X_val, y_val),callbacks=callbacks_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fd58ba92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the saved neural network model\n",
    "# DL_model = tf.keras.models.load_model('/mnt/code/pred_2020/models/hap_dnn_2020.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "aec11ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-15 16:33:36.062617: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 19124412608 exceeds 10% of free system memory.\n",
      "2023-08-15 16:34:06.207505: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 8100607376 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>RMSE_train</th>\n",
       "      <th>RMSE_val</th>\n",
       "      <th>RMSE_test</th>\n",
       "      <th>corr_train</th>\n",
       "      <th>corr_val</th>\n",
       "      <th>corr_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LightGBM_hapCat</td>\n",
       "      <td>2.713939</td>\n",
       "      <td>4.069071</td>\n",
       "      <td>8.249353</td>\n",
       "      <td>0.971496</td>\n",
       "      <td>0.928069</td>\n",
       "      <td>0.798767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DNN_hapCat</td>\n",
       "      <td>3.487118</td>\n",
       "      <td>4.351017</td>\n",
       "      <td>8.083833</td>\n",
       "      <td>0.954041</td>\n",
       "      <td>0.918706</td>\n",
       "      <td>0.774208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Method  RMSE_train  RMSE_val  RMSE_test  corr_train  corr_val  \\\n",
       "0  LightGBM_hapCat    2.713939  4.069071   8.249353    0.971496  0.928069   \n",
       "0       DNN_hapCat    3.487118  4.351017   8.083833    0.954041  0.918706   \n",
       "\n",
       "   corr_test  \n",
       "0   0.798767  \n",
       "0   0.774208  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# output prediction result\n",
    "metrics = pred_rmse_corr(DL_model,'DNN_hapCat',X_train,y_train,\n",
    "                         X_val,y_val,testHap,testPheno['YLD_BE_BLUP'],metrics)\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09da910b",
   "metadata": {},
   "source": [
    "# ElaticNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "db6452e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import pearsonr\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1cafb32d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 90672.18889941768, tolerance: 277.7539127609968\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "elsnt = ElasticNet(alpha=0.001, l1_ratio=0.25,random_state=seed)\n",
    "\n",
    "# fit the model on training data\n",
    "elsnt.fit(X_train, y_train)\n",
    "\n",
    "# save the model to disk\n",
    "filename = '/mnt/code/pred_2020/models/hap_elasticnet_2020.sav'\n",
    "pickle.dump(elsnt, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8be9cd65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>RMSE_train</th>\n",
       "      <th>RMSE_val</th>\n",
       "      <th>RMSE_test</th>\n",
       "      <th>corr_train</th>\n",
       "      <th>corr_val</th>\n",
       "      <th>corr_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LightGBM_hapCat</td>\n",
       "      <td>2.713939</td>\n",
       "      <td>4.069071</td>\n",
       "      <td>8.249353</td>\n",
       "      <td>0.971496</td>\n",
       "      <td>0.928069</td>\n",
       "      <td>0.798767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DNN_hapCat</td>\n",
       "      <td>3.487118</td>\n",
       "      <td>4.351017</td>\n",
       "      <td>8.083833</td>\n",
       "      <td>0.954041</td>\n",
       "      <td>0.918706</td>\n",
       "      <td>0.774208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>elasticNet_obs</td>\n",
       "      <td>3.193885</td>\n",
       "      <td>3.857174</td>\n",
       "      <td>8.999560</td>\n",
       "      <td>0.959152</td>\n",
       "      <td>0.935746</td>\n",
       "      <td>0.713221</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Method  RMSE_train  RMSE_val  RMSE_test  corr_train  corr_val  \\\n",
       "0  LightGBM_hapCat    2.713939  4.069071   8.249353    0.971496  0.928069   \n",
       "0       DNN_hapCat    3.487118  4.351017   8.083833    0.954041  0.918706   \n",
       "0   elasticNet_obs    3.193885  3.857174   8.999560    0.959152  0.935746   \n",
       "\n",
       "   corr_test  \n",
       "0   0.798767  \n",
       "0   0.774208  \n",
       "0   0.713221  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the model\n",
    "# filename = '/mnt/code/pred_2020/models/hap_elasticnet_2020.sav'\n",
    "# elsnt = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "# run the model\n",
    "metrics = pred_rmse_corr(elsnt,'elasticNet_obs',X_train,y_train,X_val,y_val,\n",
    "                         testHap,testPheno['YLD_BE_BLUP'],metrics)\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "bb09ccf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "testPheno['pred_hap_elsnt'] = elsnt.predict(testHap)\n",
    "testPheno['pred_hap_lgbm'] = gbm.predict(testHap)\n",
    "testPheno['pred_hap_dnn'] = DL_model.predict(testHap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e26f88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "36749c51",
   "metadata": {},
   "source": [
    "# Infinium marker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "95463ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyreadr\n",
    "\n",
    "# read in the marker data - train\n",
    "result = pyreadr.read_r('/mnt/fpImp/train_fpGenoImp_hybrid.rds') # also works for RData\n",
    "# done! \n",
    "# result is a dictionary where keys are the name of objects and the values python\n",
    "# objects. In the case of Rds there is only one object with None as key\n",
    "mkData = result[None] # extract the pandas data frame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a8bf16c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33475, 41169)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mkData.head()\n",
    "mkData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2b203836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct marker data for test and train data\n",
    "X_test = mkData.loc[testPheno['LINE_NAME'],]\n",
    "mkData = mkData.loc[trainPheno['LINE_NAME'],]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "df41126d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splite the train data into train, validationa and test\n",
    "seed = 20230510\n",
    "np.random.seed(seed)\n",
    "X_train, X_val, y_train, y_val = train_test_split(mkData, trainPheno['YLD_BE_BLUP'], test_size=0.1, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "44602a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21812, 41169)\n",
      "(2424, 41169)\n",
      "(9239, 41169)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fd31dd",
   "metadata": {},
   "source": [
    "# ElasticNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "37e57baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 103048.43066260163, tolerance: 277.7539127609968\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "elsnt = ElasticNet(alpha=0.001, l1_ratio=0.25,random_state=seed)\n",
    "\n",
    "# fit the model on training data\n",
    "elsnt.fit(X_train, y_train)\n",
    "\n",
    "# save the model to disk\n",
    "filename = '/mnt/code/pred_2020/models/inf_elasticnet_2020.sav'\n",
    "pickle.dump(elsnt, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "37d89043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>RMSE_train</th>\n",
       "      <th>RMSE_val</th>\n",
       "      <th>RMSE_test</th>\n",
       "      <th>corr_train</th>\n",
       "      <th>corr_val</th>\n",
       "      <th>corr_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LightGBM_hapCat</td>\n",
       "      <td>2.713939</td>\n",
       "      <td>4.069071</td>\n",
       "      <td>8.249353</td>\n",
       "      <td>0.971496</td>\n",
       "      <td>0.928069</td>\n",
       "      <td>0.798767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DNN_hapCat</td>\n",
       "      <td>3.487118</td>\n",
       "      <td>4.351017</td>\n",
       "      <td>8.083833</td>\n",
       "      <td>0.954041</td>\n",
       "      <td>0.918706</td>\n",
       "      <td>0.774208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>elasticNet_obs</td>\n",
       "      <td>3.193885</td>\n",
       "      <td>3.857174</td>\n",
       "      <td>8.999560</td>\n",
       "      <td>0.959152</td>\n",
       "      <td>0.935746</td>\n",
       "      <td>0.713221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>elasticNet_inf</td>\n",
       "      <td>3.191491</td>\n",
       "      <td>3.825991</td>\n",
       "      <td>9.067572</td>\n",
       "      <td>0.959212</td>\n",
       "      <td>0.936813</td>\n",
       "      <td>0.711304</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Method  RMSE_train  RMSE_val  RMSE_test  corr_train  corr_val  \\\n",
       "0  LightGBM_hapCat    2.713939  4.069071   8.249353    0.971496  0.928069   \n",
       "0       DNN_hapCat    3.487118  4.351017   8.083833    0.954041  0.918706   \n",
       "0   elasticNet_obs    3.193885  3.857174   8.999560    0.959152  0.935746   \n",
       "0   elasticNet_inf    3.191491  3.825991   9.067572    0.959212  0.936813   \n",
       "\n",
       "   corr_test  \n",
       "0   0.798767  \n",
       "0   0.774208  \n",
       "0   0.713221  \n",
       "0   0.711304  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the model\n",
    "# filename = '/mnt/code/pred_2020/models/inf_elasticnet_2020.sav'\n",
    "# elsnt = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "# run the model\n",
    "metrics = pred_rmse_corr(elsnt,'elasticNet_inf',X_train,y_train,X_val,y_val,\n",
    "                         X_test,testPheno['YLD_BE_BLUP'],metrics)\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8bfda87",
   "metadata": {},
   "source": [
    "# LightGBM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "949925c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "gbm = lgb.LGBMRegressor(num_leaves=30,\n",
    "                        learning_rate=0.1,\n",
    "                        n_estimators=900,\n",
    "                       bagging_fraction =  0.7,\n",
    "                       feature_fraction = 0.5,\n",
    "                       objective = \"regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "dab67a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 5.097132 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 186210\n",
      "[LightGBM] [Info] Number of data points in the train set: 21812, number of used features: 40875\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Info] Start training from score 4.967134\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "Early stopping, best iteration is:\n",
      "[444]\tvalid_0's l2: 18.2844\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<lightgbm.basic.Booster at 0x7f649853a940>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbm.fit(X_train, y_train,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        eval_metric='mse',\n",
    "        callbacks=[lgb.early_stopping(5)])\n",
    "\n",
    "# save model\n",
    "gbm.booster_.save_model('/mnt/code/pred_2020/models/inf_lgbr_obs_30_900.txt')\n",
    "\n",
    "# load model later\n",
    "    #model = lightgbm.Booster(model_file='file.txt')\n",
    "    #model.predict(predict[num_columns])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "88fd943c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>RMSE_train</th>\n",
       "      <th>RMSE_val</th>\n",
       "      <th>RMSE_test</th>\n",
       "      <th>corr_train</th>\n",
       "      <th>corr_val</th>\n",
       "      <th>corr_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LightGBM_hapCat</td>\n",
       "      <td>2.713939</td>\n",
       "      <td>4.069071</td>\n",
       "      <td>8.249353</td>\n",
       "      <td>0.971496</td>\n",
       "      <td>0.928069</td>\n",
       "      <td>0.798767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DNN_hapCat</td>\n",
       "      <td>3.487118</td>\n",
       "      <td>4.351017</td>\n",
       "      <td>8.083833</td>\n",
       "      <td>0.954041</td>\n",
       "      <td>0.918706</td>\n",
       "      <td>0.774208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>elasticNet_obs</td>\n",
       "      <td>3.193885</td>\n",
       "      <td>3.857174</td>\n",
       "      <td>8.999560</td>\n",
       "      <td>0.959152</td>\n",
       "      <td>0.935746</td>\n",
       "      <td>0.713221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>elasticNet_inf</td>\n",
       "      <td>3.191491</td>\n",
       "      <td>3.825991</td>\n",
       "      <td>9.067572</td>\n",
       "      <td>0.959212</td>\n",
       "      <td>0.936813</td>\n",
       "      <td>0.711304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LightGBM_inf</td>\n",
       "      <td>2.583351</td>\n",
       "      <td>4.276026</td>\n",
       "      <td>8.362801</td>\n",
       "      <td>0.974408</td>\n",
       "      <td>0.920226</td>\n",
       "      <td>0.793576</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Method  RMSE_train  RMSE_val  RMSE_test  corr_train  corr_val  \\\n",
       "0  LightGBM_hapCat    2.713939  4.069071   8.249353    0.971496  0.928069   \n",
       "0       DNN_hapCat    3.487118  4.351017   8.083833    0.954041  0.918706   \n",
       "0   elasticNet_obs    3.193885  3.857174   8.999560    0.959152  0.935746   \n",
       "0   elasticNet_inf    3.191491  3.825991   9.067572    0.959212  0.936813   \n",
       "0     LightGBM_inf    2.583351  4.276026   8.362801    0.974408  0.920226   \n",
       "\n",
       "   corr_test  \n",
       "0   0.798767  \n",
       "0   0.774208  \n",
       "0   0.713221  \n",
       "0   0.711304  \n",
       "0   0.793576  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# output prediction result\n",
    "metrics = pred_rmse_corr(gbm,'LightGBM_inf',X_train,y_train,X_val,y_val,\n",
    "                         X_test,testPheno['YLD_BE_BLUP'],metrics)\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01550a4c",
   "metadata": {},
   "source": [
    "# DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c61e96c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "682/682 [==============================] - 10s 14ms/step - loss: 59.1135 - val_loss: 37.0281\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 37.02813, saving model to /mnt/code/pred_2020/models/inf_dnn_obs.h5\n",
      "Epoch 2/50\n",
      "682/682 [==============================] - 8s 12ms/step - loss: 35.4609 - val_loss: 35.0848\n",
      "\n",
      "Epoch 00002: val_loss improved from 37.02813 to 35.08479, saving model to /mnt/code/pred_2020/models/inf_dnn_obs.h5\n",
      "Epoch 3/50\n",
      "682/682 [==============================] - 8s 12ms/step - loss: 34.6222 - val_loss: 34.7943\n",
      "\n",
      "Epoch 00003: val_loss improved from 35.08479 to 34.79431, saving model to /mnt/code/pred_2020/models/inf_dnn_obs.h5\n",
      "Epoch 4/50\n",
      "682/682 [==============================] - 8s 12ms/step - loss: 30.3198 - val_loss: 29.7951\n",
      "\n",
      "Epoch 00004: val_loss improved from 34.79431 to 29.79510, saving model to /mnt/code/pred_2020/models/inf_dnn_obs.h5\n",
      "Epoch 5/50\n",
      "682/682 [==============================] - 8s 12ms/step - loss: 27.2064 - val_loss: 28.9439\n",
      "\n",
      "Epoch 00005: val_loss improved from 29.79510 to 28.94386, saving model to /mnt/code/pred_2020/models/inf_dnn_obs.h5\n",
      "Epoch 6/50\n",
      "682/682 [==============================] - 8s 12ms/step - loss: 27.9893 - val_loss: 27.4273\n",
      "\n",
      "Epoch 00006: val_loss improved from 28.94386 to 27.42729, saving model to /mnt/code/pred_2020/models/inf_dnn_obs.h5\n",
      "Epoch 7/50\n",
      "682/682 [==============================] - 8s 12ms/step - loss: 25.7508 - val_loss: 25.1498\n",
      "\n",
      "Epoch 00007: val_loss improved from 27.42729 to 25.14984, saving model to /mnt/code/pred_2020/models/inf_dnn_obs.h5\n",
      "Epoch 8/50\n",
      "682/682 [==============================] - 8s 12ms/step - loss: 24.7391 - val_loss: 29.3314\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 25.14984\n",
      "Epoch 9/50\n",
      "682/682 [==============================] - 8s 12ms/step - loss: 24.5857 - val_loss: 23.8017\n",
      "\n",
      "Epoch 00009: val_loss improved from 25.14984 to 23.80165, saving model to /mnt/code/pred_2020/models/inf_dnn_obs.h5\n",
      "Epoch 10/50\n",
      "682/682 [==============================] - 8s 12ms/step - loss: 22.4502 - val_loss: 26.7701\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 23.80165\n",
      "Epoch 11/50\n",
      "682/682 [==============================] - 8s 12ms/step - loss: 20.6439 - val_loss: 23.5374\n",
      "\n",
      "Epoch 00011: val_loss improved from 23.80165 to 23.53738, saving model to /mnt/code/pred_2020/models/inf_dnn_obs.h5\n",
      "Epoch 12/50\n",
      "682/682 [==============================] - 8s 12ms/step - loss: 20.2461 - val_loss: 24.2622\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 23.53738\n",
      "Epoch 13/50\n",
      "682/682 [==============================] - 8s 12ms/step - loss: 19.7262 - val_loss: 24.6502\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 23.53738\n",
      "Epoch 14/50\n",
      "682/682 [==============================] - 8s 12ms/step - loss: 19.4661 - val_loss: 22.1104\n",
      "\n",
      "Epoch 00014: val_loss improved from 23.53738 to 22.11042, saving model to /mnt/code/pred_2020/models/inf_dnn_obs.h5\n",
      "Epoch 15/50\n",
      "682/682 [==============================] - 8s 12ms/step - loss: 18.8400 - val_loss: 20.8505\n",
      "\n",
      "Epoch 00015: val_loss improved from 22.11042 to 20.85052, saving model to /mnt/code/pred_2020/models/inf_dnn_obs.h5\n",
      "Epoch 16/50\n",
      "682/682 [==============================] - 8s 12ms/step - loss: 17.1785 - val_loss: 24.7841\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 20.85052\n",
      "Epoch 17/50\n",
      "682/682 [==============================] - 8s 12ms/step - loss: 17.8979 - val_loss: 22.5617\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 20.85052\n",
      "Epoch 18/50\n",
      "682/682 [==============================] - 8s 12ms/step - loss: 16.4514 - val_loss: 20.5042\n",
      "\n",
      "Epoch 00018: val_loss improved from 20.85052 to 20.50425, saving model to /mnt/code/pred_2020/models/inf_dnn_obs.h5\n",
      "Epoch 19/50\n",
      "682/682 [==============================] - 8s 12ms/step - loss: 16.8526 - val_loss: 21.3630\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 20.50425\n",
      "Epoch 20/50\n",
      "682/682 [==============================] - 8s 12ms/step - loss: 15.9167 - val_loss: 22.4611\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 20.50425\n",
      "Epoch 21/50\n",
      "682/682 [==============================] - 8s 12ms/step - loss: 16.0152 - val_loss: 25.2403\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 20.50425\n",
      "Epoch 22/50\n",
      "682/682 [==============================] - 8s 12ms/step - loss: 15.6345 - val_loss: 21.6375\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 20.50425\n",
      "Epoch 23/50\n",
      "682/682 [==============================] - 8s 12ms/step - loss: 15.0644 - val_loss: 21.4886\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 20.50425\n",
      "Epoch 24/50\n",
      "682/682 [==============================] - 8s 12ms/step - loss: 14.7645 - val_loss: 20.4718\n",
      "\n",
      "Epoch 00024: val_loss improved from 20.50425 to 20.47181, saving model to /mnt/code/pred_2020/models/inf_dnn_obs.h5\n",
      "Epoch 25/50\n",
      "682/682 [==============================] - 8s 12ms/step - loss: 14.7645 - val_loss: 21.1239\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 20.47181\n",
      "Epoch 26/50\n",
      "682/682 [==============================] - 8s 12ms/step - loss: 13.6789 - val_loss: 21.6749\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 20.47181\n",
      "Epoch 27/50\n",
      "682/682 [==============================] - 8s 12ms/step - loss: 14.1144 - val_loss: 20.7847\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 20.47181\n",
      "Epoch 28/50\n",
      "682/682 [==============================] - 8s 12ms/step - loss: 14.1580 - val_loss: 19.8409\n",
      "\n",
      "Epoch 00028: val_loss improved from 20.47181 to 19.84092, saving model to /mnt/code/pred_2020/models/inf_dnn_obs.h5\n",
      "Epoch 29/50\n",
      "682/682 [==============================] - 8s 12ms/step - loss: 14.7404 - val_loss: 20.2262\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 19.84092\n",
      "Epoch 30/50\n",
      "682/682 [==============================] - 8s 11ms/step - loss: 12.9098 - val_loss: 21.8686\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 19.84092\n",
      "Epoch 31/50\n",
      "682/682 [==============================] - 8s 12ms/step - loss: 13.4821 - val_loss: 19.4454\n",
      "\n",
      "Epoch 00031: val_loss improved from 19.84092 to 19.44543, saving model to /mnt/code/pred_2020/models/inf_dnn_obs.h5\n",
      "Epoch 32/50\n",
      "682/682 [==============================] - 8s 12ms/step - loss: 12.7803 - val_loss: 22.6398\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 19.44543\n",
      "Epoch 33/50\n",
      "682/682 [==============================] - 8s 12ms/step - loss: 13.5633 - val_loss: 20.9643\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 19.44543\n",
      "Epoch 34/50\n",
      "682/682 [==============================] - 8s 12ms/step - loss: 12.5376 - val_loss: 20.0289\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 19.44543\n",
      "Epoch 35/50\n",
      "682/682 [==============================] - 8s 12ms/step - loss: 12.2526 - val_loss: 20.5603\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 19.44543\n",
      "Epoch 36/50\n",
      "341/682 [==============>...............] - ETA: 3s - loss: 12.6266"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(20230516)\n",
    "\n",
    "DL_model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[X_train.shape[1]], name = 'input_layer'),\n",
    "    keras.layers.Dense(100, activation=\"relu\", name = 'hidden_layer1'),\n",
    "    keras.layers.Dense(300, activation=\"relu\", name = 'hidden_layer2'),\n",
    "    keras.layers.Dense(1, name = 'output_layer')\n",
    "])\n",
    "\n",
    "DL_model.compile(loss=\"mean_squared_error\",optimizer=tf.keras.optimizers.Adam(0.001)) \n",
    "\n",
    "# define the checkpoint\n",
    "filepath = \"/mnt/code/pred_2020/models/inf_dnn_obs.h5\"\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "early_stopping = keras.callbacks.EarlyStopping(patience=8,restore_best_weights=True)\n",
    "callbacks_list = [checkpoint,early_stopping]\n",
    "\n",
    "# fit the model\n",
    "history = DL_model.fit(X_train,y_train,epochs=50,validation_data = (X_val, y_val),callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c105eca7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>RMSE_train</th>\n",
       "      <th>RMSE_val</th>\n",
       "      <th>RMSE_test</th>\n",
       "      <th>corr_train</th>\n",
       "      <th>corr_val</th>\n",
       "      <th>corr_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LightGBM_hapCat</td>\n",
       "      <td>2.713939</td>\n",
       "      <td>4.069071</td>\n",
       "      <td>8.249353</td>\n",
       "      <td>0.971496</td>\n",
       "      <td>0.928069</td>\n",
       "      <td>0.798767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DNN_hapCat</td>\n",
       "      <td>3.487118</td>\n",
       "      <td>4.351017</td>\n",
       "      <td>8.083833</td>\n",
       "      <td>0.954041</td>\n",
       "      <td>0.918706</td>\n",
       "      <td>0.774208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>elasticNet_obs</td>\n",
       "      <td>3.193885</td>\n",
       "      <td>3.857174</td>\n",
       "      <td>8.999560</td>\n",
       "      <td>0.959152</td>\n",
       "      <td>0.935746</td>\n",
       "      <td>0.713221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>elasticNet_inf</td>\n",
       "      <td>3.191491</td>\n",
       "      <td>3.825991</td>\n",
       "      <td>9.067572</td>\n",
       "      <td>0.959212</td>\n",
       "      <td>0.936813</td>\n",
       "      <td>0.711304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LightGBM_inf</td>\n",
       "      <td>2.583351</td>\n",
       "      <td>4.276026</td>\n",
       "      <td>8.362801</td>\n",
       "      <td>0.974408</td>\n",
       "      <td>0.920226</td>\n",
       "      <td>0.793576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DNN_inf</td>\n",
       "      <td>3.454239</td>\n",
       "      <td>4.409698</td>\n",
       "      <td>8.136475</td>\n",
       "      <td>0.953973</td>\n",
       "      <td>0.915222</td>\n",
       "      <td>0.779435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Method  RMSE_train  RMSE_val  RMSE_test  corr_train  corr_val  \\\n",
       "0  LightGBM_hapCat    2.713939  4.069071   8.249353    0.971496  0.928069   \n",
       "0       DNN_hapCat    3.487118  4.351017   8.083833    0.954041  0.918706   \n",
       "0   elasticNet_obs    3.193885  3.857174   8.999560    0.959152  0.935746   \n",
       "0   elasticNet_inf    3.191491  3.825991   9.067572    0.959212  0.936813   \n",
       "0     LightGBM_inf    2.583351  4.276026   8.362801    0.974408  0.920226   \n",
       "0          DNN_inf    3.454239  4.409698   8.136475    0.953973  0.915222   \n",
       "\n",
       "   corr_test  \n",
       "0   0.798767  \n",
       "0   0.774208  \n",
       "0   0.713221  \n",
       "0   0.711304  \n",
       "0   0.793576  \n",
       "0   0.779435  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the saved neural network model\n",
    "# DL_model = tf.keras.models.load_model('/mnt/ML_HBLUP/NA_RM105_110_115/models/inf_dnn_obs.h5')\n",
    "# output prediction result\n",
    "metrics = pred_rmse_corr(DL_model,'DNN_inf',X_train,y_train,X_val,y_val,\n",
    "                         X_test,testPheno['YLD_BE_BLUP'],metrics)\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba774884",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5397c34b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7\n"
     ]
    }
   ],
   "source": [
    "testPheno['pred_inf_elsnt'] = elsnt.predict(X_test)\n",
    "testPheno['pred_inf_lgbm'] = gbm.predict(X_test)\n",
    "testPheno['pred_inf_dnn'] = DL_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d70cd324",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LINE_NAME</th>\n",
       "      <th>FEMALE</th>\n",
       "      <th>MALE</th>\n",
       "      <th>YLD_BE_BLUP</th>\n",
       "      <th>MST_BE_BLUP</th>\n",
       "      <th>pred_hap_elsnt</th>\n",
       "      <th>pred_hap_lgbm</th>\n",
       "      <th>pred_inf_elsnt</th>\n",
       "      <th>pred_inf_lgbm</th>\n",
       "      <th>pred_inf_dnn</th>\n",
       "      <th>pred_hap_dnn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01DHD10+LH287</td>\n",
       "      <td>01DHD10</td>\n",
       "      <td>LH287</td>\n",
       "      <td>-15.661</td>\n",
       "      <td>-0.219</td>\n",
       "      <td>-11.380652</td>\n",
       "      <td>-8.602051</td>\n",
       "      <td>-10.990887</td>\n",
       "      <td>-8.858128</td>\n",
       "      <td>-3.705641</td>\n",
       "      <td>-6.430006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01DHD16+83INI14</td>\n",
       "      <td>01DHD16</td>\n",
       "      <td>83INI14</td>\n",
       "      <td>-41.839</td>\n",
       "      <td>-4.254</td>\n",
       "      <td>-35.774050</td>\n",
       "      <td>-26.850505</td>\n",
       "      <td>-46.533695</td>\n",
       "      <td>-27.879312</td>\n",
       "      <td>-32.630455</td>\n",
       "      <td>-25.352154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>01DKD2+19HGZ1</td>\n",
       "      <td>01DKD2</td>\n",
       "      <td>19HGZ1</td>\n",
       "      <td>-5.917</td>\n",
       "      <td>0.091</td>\n",
       "      <td>-10.031257</td>\n",
       "      <td>-7.806338</td>\n",
       "      <td>-11.747356</td>\n",
       "      <td>-5.486347</td>\n",
       "      <td>-11.354566</td>\n",
       "      <td>-6.807303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>01DKD2+80IDM2</td>\n",
       "      <td>01DKD2</td>\n",
       "      <td>80IDM2</td>\n",
       "      <td>-4.271</td>\n",
       "      <td>0.272</td>\n",
       "      <td>-9.682158</td>\n",
       "      <td>-3.608324</td>\n",
       "      <td>-9.204932</td>\n",
       "      <td>-2.773324</td>\n",
       "      <td>-6.941370</td>\n",
       "      <td>-6.797855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>01DKD2+93IDI3</td>\n",
       "      <td>01DKD2</td>\n",
       "      <td>93IDI3</td>\n",
       "      <td>-14.926</td>\n",
       "      <td>0.210</td>\n",
       "      <td>-17.092687</td>\n",
       "      <td>-9.716184</td>\n",
       "      <td>-18.170208</td>\n",
       "      <td>-9.706514</td>\n",
       "      <td>-13.007492</td>\n",
       "      <td>-10.375535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          LINE_NAME   FEMALE     MALE  YLD_BE_BLUP  MST_BE_BLUP  \\\n",
       "0     01DHD10+LH287  01DHD10    LH287      -15.661       -0.219   \n",
       "1   01DHD16+83INI14  01DHD16  83INI14      -41.839       -4.254   \n",
       "8     01DKD2+19HGZ1   01DKD2   19HGZ1       -5.917        0.091   \n",
       "9     01DKD2+80IDM2   01DKD2   80IDM2       -4.271        0.272   \n",
       "10    01DKD2+93IDI3   01DKD2   93IDI3      -14.926        0.210   \n",
       "\n",
       "    pred_hap_elsnt  pred_hap_lgbm  pred_inf_elsnt  pred_inf_lgbm  \\\n",
       "0       -11.380652      -8.602051      -10.990887      -8.858128   \n",
       "1       -35.774050     -26.850505      -46.533695     -27.879312   \n",
       "8       -10.031257      -7.806338      -11.747356      -5.486347   \n",
       "9        -9.682158      -3.608324       -9.204932      -2.773324   \n",
       "10      -17.092687      -9.716184      -18.170208      -9.706514   \n",
       "\n",
       "    pred_inf_dnn  pred_hap_dnn  \n",
       "0      -3.705641     -6.430006  \n",
       "1     -32.630455    -25.352154  \n",
       "8     -11.354566     -6.807303  \n",
       "9      -6.941370     -6.797855  \n",
       "10    -13.007492    -10.375535  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testPheno.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "082cce32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YLD_BE_BLUP</th>\n",
       "      <th>MST_BE_BLUP</th>\n",
       "      <th>pred_hap_elsnt</th>\n",
       "      <th>pred_hap_lgbm</th>\n",
       "      <th>pred_inf_elsnt</th>\n",
       "      <th>pred_inf_lgbm</th>\n",
       "      <th>pred_inf_dnn</th>\n",
       "      <th>pred_hap_dnn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>YLD_BE_BLUP</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.408067</td>\n",
       "      <td>0.713221</td>\n",
       "      <td>0.798767</td>\n",
       "      <td>0.711304</td>\n",
       "      <td>0.793576</td>\n",
       "      <td>0.779435</td>\n",
       "      <td>0.774208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MST_BE_BLUP</th>\n",
       "      <td>0.408067</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.448829</td>\n",
       "      <td>0.499593</td>\n",
       "      <td>0.453499</td>\n",
       "      <td>0.521477</td>\n",
       "      <td>0.473680</td>\n",
       "      <td>0.491369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred_hap_elsnt</th>\n",
       "      <td>0.713221</td>\n",
       "      <td>0.448829</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.846440</td>\n",
       "      <td>0.871783</td>\n",
       "      <td>0.839236</td>\n",
       "      <td>0.865681</td>\n",
       "      <td>0.886647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred_hap_lgbm</th>\n",
       "      <td>0.798767</td>\n",
       "      <td>0.499593</td>\n",
       "      <td>0.846440</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.843706</td>\n",
       "      <td>0.959050</td>\n",
       "      <td>0.914707</td>\n",
       "      <td>0.926854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred_inf_elsnt</th>\n",
       "      <td>0.711304</td>\n",
       "      <td>0.453499</td>\n",
       "      <td>0.871783</td>\n",
       "      <td>0.843706</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.845586</td>\n",
       "      <td>0.884750</td>\n",
       "      <td>0.871169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred_inf_lgbm</th>\n",
       "      <td>0.793576</td>\n",
       "      <td>0.521477</td>\n",
       "      <td>0.839236</td>\n",
       "      <td>0.959050</td>\n",
       "      <td>0.845586</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.916444</td>\n",
       "      <td>0.913621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred_inf_dnn</th>\n",
       "      <td>0.779435</td>\n",
       "      <td>0.473680</td>\n",
       "      <td>0.865681</td>\n",
       "      <td>0.914707</td>\n",
       "      <td>0.884750</td>\n",
       "      <td>0.916444</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.940339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred_hap_dnn</th>\n",
       "      <td>0.774208</td>\n",
       "      <td>0.491369</td>\n",
       "      <td>0.886647</td>\n",
       "      <td>0.926854</td>\n",
       "      <td>0.871169</td>\n",
       "      <td>0.913621</td>\n",
       "      <td>0.940339</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                YLD_BE_BLUP  MST_BE_BLUP  pred_hap_elsnt  pred_hap_lgbm  \\\n",
       "YLD_BE_BLUP        1.000000     0.408067        0.713221       0.798767   \n",
       "MST_BE_BLUP        0.408067     1.000000        0.448829       0.499593   \n",
       "pred_hap_elsnt     0.713221     0.448829        1.000000       0.846440   \n",
       "pred_hap_lgbm      0.798767     0.499593        0.846440       1.000000   \n",
       "pred_inf_elsnt     0.711304     0.453499        0.871783       0.843706   \n",
       "pred_inf_lgbm      0.793576     0.521477        0.839236       0.959050   \n",
       "pred_inf_dnn       0.779435     0.473680        0.865681       0.914707   \n",
       "pred_hap_dnn       0.774208     0.491369        0.886647       0.926854   \n",
       "\n",
       "                pred_inf_elsnt  pred_inf_lgbm  pred_inf_dnn  pred_hap_dnn  \n",
       "YLD_BE_BLUP           0.711304       0.793576      0.779435      0.774208  \n",
       "MST_BE_BLUP           0.453499       0.521477      0.473680      0.491369  \n",
       "pred_hap_elsnt        0.871783       0.839236      0.865681      0.886647  \n",
       "pred_hap_lgbm         0.843706       0.959050      0.914707      0.926854  \n",
       "pred_inf_elsnt        1.000000       0.845586      0.884750      0.871169  \n",
       "pred_inf_lgbm         0.845586       1.000000      0.916444      0.913621  \n",
       "pred_inf_dnn          0.884750       0.916444      1.000000      0.940339  \n",
       "pred_hap_dnn          0.871169       0.913621      0.940339      1.000000  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testPheno.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5fdf8889",
   "metadata": {},
   "outputs": [],
   "source": [
    "testPheno.to_csv(\"pred_2020.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
